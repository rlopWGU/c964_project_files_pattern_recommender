{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1483bf16-56bc-4e68-9566-5dd400f1b2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing URL extraction from Ravelry. Please wait...\n",
      "Executing data scraping from Ravelry. This process may take several minutes or hours. Please wait...\n",
      "Executing data preprocessing. Please wait...\n",
      "Executing TF-IDF on data. Please wait...\n",
      "Executing Word Embedding on data. Please wait...\n",
      "Executing Cosine Similarity processing on TF-IDF data. Please wait...\n",
      "Executing Cosine Similarity processing on Word Embedding data. Please wait...\n",
      "Executing Matrices Normalization processing on Word Embedding + TF-DF Cosine Similarity data. Please wait...\n",
      "Data processing complete. Hybrid TF-IDF + Word Embedding Cosine Similarity Matrix updated.\n",
      "Program is now ready to execute search queries.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'current problem appears to be that when import data_preprocessor runs, the installation/import messages in that notebook are not run (which would solve the nltk is not defined issue). \\nSo then should we move forward with a separate notebook for all installations? Or would this not solve the problem because we have to import libs per notebook??'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install import-ipynb\n",
    "import import_ipynb\n",
    "import url_extraction\n",
    "import data_scraper\n",
    "import data_preprocessor\n",
    "import data_tfidf\n",
    "import data_word_embedding\n",
    "import data_cosim_tfidf\n",
    "import data_cosim_word_embedding\n",
    "import data_normalize_matrices\n",
    "\n",
    "#Calls scripts to sequentially perform pattern URL extraction, data scraping, and all data processing\n",
    "def execute_data_collection_processing():\n",
    "    print(\"Executing URL extraction from Ravelry. Please wait...\")\n",
    "    url_extraction.extract_urls()\n",
    "\n",
    "    print(\"Executing data scraping from Ravelry. This process may take several minutes or hours. Please wait...\")\n",
    "    data_scraper.scrape_data()\n",
    "\n",
    "    print(\"Executing data preprocessing. Please wait...\")\n",
    "    data_preprocessor.preprocess_data()\n",
    "\n",
    "    print(\"Executing TF-IDF on data. Please wait...\")\n",
    "    data_tfidf.process_data()\n",
    "    \n",
    "    print(\"Executing Word Embedding on data. Please wait...\")\n",
    "    data_word_embedding.process_data()\n",
    "    \n",
    "    print(\"Executing Cosine Similarity processing on TF-IDF data. Please wait...\")\n",
    "    data_cosim_tfidf.process_data()\n",
    "\n",
    "    print(\"Executing Cosine Similarity processing on Word Embedding data. Please wait...\")\n",
    "    data_cosim_word_embedding.process_data()\n",
    "\n",
    "    print(\"Executing Matrices Normalization processing on Word Embedding + TF-DF Cosine Similarity data. Please wait...\")\n",
    "    data_normalize_matrices.process_data()\n",
    "\n",
    "    print(\"Data processing complete. Hybrid TF-IDF + Word Embedding Cosine Similarity Matrix updated.\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
